{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill Gates.jpg', 'Elon.jpg', 'Uthand.JPG', 'Vathsav.JPG']\n"
     ]
    }
   ],
   "source": [
    "path = 'Timg'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill Gates', 'Elon', 'Uthand', 'Vathsav']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "for i in myList:\n",
    "    curImg = cv2.imread(f'{path}/{i}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(i)[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime(\"%HH:%MM:%SS\")\n",
    "            f.writelines(f'\\n{name},{dtString}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding complete\n",
      "[0.84888561 0.88636346 0.55185591 0.48217885]\n",
      "VATHSAV\n",
      "[0.83580703 0.90478557 0.74456023 0.54846998]\n",
      "VATHSAV\n",
      "[0.84874985 0.88432737 0.64312554 0.52717909]\n",
      "VATHSAV\n",
      "[0.86008439 0.88583342 0.570191   0.52432758]\n",
      "VATHSAV\n",
      "[0.78718051 0.82204678 0.59532542 0.57640469]\n",
      "VATHSAV\n",
      "[0.83273086 0.81239455 0.53753982 0.4631831 ]\n",
      "VATHSAV\n",
      "[0.83372448 0.79189501 0.5325808  0.5544988 ]\n",
      "UTHAND\n",
      "[0.87161817 0.87748271 0.54283045 0.48084649]\n",
      "VATHSAV\n",
      "[0.74320483 0.75552312 0.67557755 0.63349184]\n",
      "[0.89371958 0.88524942 0.59958165 0.46018942]\n",
      "VATHSAV\n",
      "[0.81895621 0.72873697 0.67019545 0.66455668]\n",
      "[0.85744442 0.88277681 0.63782101 0.62352386]\n",
      "[0.90381539 0.8927251  0.46621629 0.66067666]\n",
      "UTHAND\n",
      "[0.83994373 0.8593741  0.38921971 0.65702483]\n",
      "UTHAND\n",
      "[0.80872874 0.85398455 0.37082738 0.65447535]\n",
      "UTHAND\n",
      "[0.82238166 0.77218151 0.64173516 0.65324874]\n",
      "[0.80479452 0.75258068 0.66121035 0.67053618]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "encodeListKnown = findEncodings(images)\n",
    "print(\"encoding complete\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            print(name)\n",
    "        \n",
    "            markAttendance(name)\n",
    "    cv2.imshow('Webcam', img)\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ed124f2b279c186db57d0ede455df2b109954ad4fa1a5a2c59adb747c894aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
